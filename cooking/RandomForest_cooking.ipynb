{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performance\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in the Data\n",
    "train = pd.read_json('train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the Unique Ingredients\n",
    "words = [' '.join(item) for item in train.ingredients]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer ##\n",
    "\n",
    "Convert a collection of text documents to a (sparse) matrix of token counts. \n",
    "\n",
    "*stop_words*='english'\n",
    "\n",
    "*ngram_range* : tuple (min_n, max_n)\n",
    "\n",
    "**Implements both tokenization and occurrence counting.**\n",
    "\n",
    "- tokenization extracts words of at least 2 letters\n",
    "\n",
    "- counting is achieved by assigning a unique integer index to each term corresponding to a column in the resulting matrix\n",
    "\n",
    "- note: words not seen in training corpus will be completely ignored in future calls to the **transform** method\n",
    "\n",
    "- to preserve local ordering information, extract 2-grams of words in addition to 1-grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct the Bag of Words\n",
    "vec = CountVectorizer(max_features=2000, ngram_range=(1, 2), lowercase=True, \\\n",
    "                     stop_words=None)\n",
    "bag_of_words = vec.fit_transform(words).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier ##\n",
    "\n",
    "*n_estimators* = number of trees in the forest\n",
    "\n",
    "*criterion* = 'gini' (for Gini impurity) or \"entropy\" (for information gain)\n",
    "\n",
    "*max_features* = \"auto\" (that is, sqrt(n_features))\n",
    "\n",
    "*max_depth* = None (The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. Ignored if max_leaf_nodes is not None.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Random Forest Classification\n",
    "random_forest = RandomForestClassifier(n_estimators=200, criterion='gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##random_forest.fit## \n",
    "\n",
    "Build a forest of trees from the training set (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Training finished in 170.30 s\n"
     ]
    }
   ],
   "source": [
    "# Recored the time it takes to perform the search\n",
    "start = time()\n",
    "random_forest.fit(bag_of_words, train.cuisine)\n",
    "print(\"RandomForest Training finished in %.2f s\" % (time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##cross_val_predict##\n",
    "\n",
    "Generate cross-validated estimates for each input data point\n",
    "\n",
    "*estimator* = random_forest (estimator object implementing 'fit' and 'predict')\n",
    "\n",
    "*x* = bag_of_words (the data to fit)\n",
    "\n",
    "*y* = train.cuisine (the target variable to try to predict in case of supervised learning)\n",
    "\n",
    "*cv* = cross-validation generator or int (if int, determines the number of folds in StratifiedKFold, if y is binary/multiclass, or number of folds in KFold otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Evaluation finished in 148.57 s\n"
     ]
    }
   ],
   "source": [
    "# Basic Evaluation on Training Set\n",
    "start = time()\n",
    "train_pred = cross_val_predict(random_forest, bag_of_words, train.cuisine, cv=2)\n",
    "print(\"RandomForest Evaluation finished in %.2f s\" % (time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##accuracy_score##\n",
    "\n",
    "In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.730804042842\n"
     ]
    }
   ],
   "source": [
    "# Display Accuracy\n",
    "print(\"Accuracy: \", accuracy_score(train.cuisine, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in Testing Data\n",
    "test = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 18009</td>\n",
       "      <td> [baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 28583</td>\n",
       "      <td> [sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 41580</td>\n",
       "      <td> [sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 29752</td>\n",
       "      <td> [meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 35687</td>\n",
       "      <td> [ground black pepper, salt, sausage casings, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...\n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...\n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...\n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...\n",
       "4  35687  [ground black pepper, salt, sausage casings, l..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create test Bag of Words\n",
    "test_words = [' '.join(item) for item in test.ingredients]\n",
    "test_bag = vec.transform(test_words).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##random_forest.predict##\n",
    "\n",
    "Predict class for X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the Prediction\n",
    "result = random_forest.predict(test_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
