{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performance\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the Data\n",
    "train = pd.read_json('train.json')\n",
    "test = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>       greek</td>\n",
       "      <td> 10259</td>\n",
       "      <td> [romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> southern_us</td>\n",
       "      <td> 25693</td>\n",
       "      <td> [plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>    filipino</td>\n",
       "      <td> 20130</td>\n",
       "      <td> [eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>      indian</td>\n",
       "      <td> 22213</td>\n",
       "      <td>               [water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>      indian</td>\n",
       "      <td> 13162</td>\n",
       "      <td> [black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the Unique Ingredients\n",
    "words_train = [' '.join(item) for item in train.ingredients]\n",
    "words_test = [' '.join(item) for item in test.ingredients]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf term weighting\n",
    "\n",
    "Term-frequency x inverse document-frequency: a term weighting scheme to re-weight count features for very frequent words\n",
    "\n",
    "TfidfVectorizer combines all the options of CountVectorizer and TfidfTransformer (where re-weighting occurs) into a single model\n",
    "\n",
    "stop_words='english'\n",
    "\n",
    "ngram_range : tuple (min_n, max_n)\n",
    "\n",
    "max_df : ignore terms that have a doc frequency strictly higher than given threshold\n",
    "\n",
    "min_df : ignore terms that have doc freq strictly lower than given threshold\n",
    "\n",
    "max_features : if not None, build vocab that only considers top max_features ordered by term frequency across corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5)\n",
    "bag_of_words_train = vectorizer.fit_transform(words_train)\n",
    "bag_of_words_test = vectorizer.transform(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 3049)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a pipeline combining a text feature extractor with a simple\n",
    "# classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__max_df': (0.10, 0.15),\n",
    "    #'vect__max_features': (None, 1000),\n",
    "    #'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__n_estimators': (50, 60, 70),\n",
    "    #'clf__criterion': ('gini', 'entropy')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__n_estimators': (50, 60, 70), 'vect__max_df': (0.1, 0.15)}\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:   26.4s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  9.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 615.013s\n",
      "\n",
      "Best score: 0.745\n",
      "Best parameters set:\n",
      "\tclf__n_estimators: 70\n",
      "\tvect__max_df: 0.15\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# find the best parameters for both the feature extraction and the\n",
    "# classifier\n",
    "grid_search = GridSearchCV(pipeline, parameters, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(words_train, train.cuisine)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "- ## SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = SelectPercentile(f_classif, percentile = 10)\n",
    "selector.fit(bag_of_words_train, train.cuisine)\n",
    "new_bag_of_words_train = selector.transform(bag_of_words_train).toarray()\n",
    "new_bag_of_words_test = selector.transform(bag_of_words_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Training finished in 55.44 s\n"
     ]
    }
   ],
   "source": [
    "## Random Forest Classification\n",
    "random_forest = RandomForestClassifier(n_estimators=200, criterion='gini')\n",
    "start = time()\n",
    "random_forest.fit(new_bag_of_words_train, train.cuisine)\n",
    "print(\"RandomForest Training finished in %.2f s\" % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Evaluation finished in 50.69 s\n"
     ]
    }
   ],
   "source": [
    "# Basic Evaluation on Training Set\n",
    "start = time()\n",
    "train_pred = cross_val_predict(random_forest, new_bag_of_words_train, train.cuisine, cv=2)\n",
    "print(\"RandomForest Evaluation finished in %.2f s\" % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.718534721175\n"
     ]
    }
   ],
   "source": [
    "# Display Accuracy\n",
    "print(\"Accuracy: \", accuracy_score(train.cuisine, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
